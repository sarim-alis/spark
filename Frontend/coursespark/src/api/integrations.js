// Real AI Integration using OpenAI API
const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY;

export const InvokeLLM = async ({ prompt, model = 'gpt-3.5-turbo', add_context_from_internet = false }) => {
  try {
    if (!OPENAI_API_KEY) {
      console.error('âŒ OpenAI API key not found');
      throw new Error('OpenAI API key is not configured. Please set VITE_OPENAI_API_KEY in your environment variables.');
    }

    console.log('ðŸ¤– Calling OpenAI API...');
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: model,
        messages: [
          {
            role: 'system',
            content: 'You are a helpful AI assistant that provides accurate and professional responses.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: 0.7,
        max_tokens: 2000
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('âŒ API Error:', errorText);
      
      if (response.status === 429) {
        throw new Error('OpenAI API rate limit exceeded. Please try again in a moment.');
      }
      
      if (response.status === 401) {
        throw new Error('Invalid OpenAI API key. Please check your configuration.');
      }
      
      throw new Error(`OpenAI API Error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    console.log('âœ… API Response received');
    
    if (!data.choices || !data.choices[0]) {
      throw new Error('No content generated');
    }
    
    const aiResponse = data.choices[0].message.content;
    
    return {
      response: aiResponse,
      usage: data.usage || { tokens: 0 }
    };
  } catch (error) {
    console.error('InvokeLLM Error:', error);
    throw error;
  }
};

export const GenerateImage = async ({ prompt, size = '1024x1024' }) => {
  // Return placeholder image
  await new Promise(resolve => setTimeout(resolve, 500));
  return {
    url: `https://placehold.co/${size}/6366f1/white?text=${encodeURIComponent(prompt.slice(0, 20))}`
  };
};

export const SendEmail = async ({ to, subject, body }) => {
  console.log('ðŸ“§ Email (simulated):', { to, subject, body });
  return { success: true, message: 'Email would be sent in production' };
};

export const UploadFile = async (file) => {
  // Simulate file upload
  await new Promise(resolve => setTimeout(resolve, 500));
  return {
    url: URL.createObjectURL(file),
    filename: file.name,
    size: file.size
  };
};

export const CreateFileSignedUrl = async (path) => {
  return { url: `https://placeholder.com/${path}` };
};

export const ExtractDataFromUploadedFile = async (fileUrl) => {
  return { data: 'Simulated extracted data', success: true };
};

export const UploadPrivateFile = async (file) => {
  return {
    url: URL.createObjectURL(file),
    filename: file.name,
    private: true
  };
};

export const Core = {
  InvokeLLM,
  GenerateImage,
  SendEmail,
  UploadFile,
  CreateFileSignedUrl,
  ExtractDataFromUploadedFile,
  UploadPrivateFile
};





